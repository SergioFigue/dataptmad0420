{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Tic Tac Toe\n",
    "\n",
    "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
    "\n",
    "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
    "\n",
    "![Tic Tac Toe Grids](tttboard.jpg)\n",
    "\n",
    "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
    "\n",
    "## Step 1: Data Engineering\n",
    "\n",
    "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
    "\n",
    "1. Read `tic-tac-toe.csv` into a dataframe.\n",
    "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
    "1. Convert the categorical values to numeric in all columns.\n",
    "1. Separate the inputs and output.\n",
    "1. Normalize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = pd.read_csv('tic-tac-toe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TL TM TR ML MM MR BL BM BR  class\n",
       "0  x  x  x  x  o  o  x  o  o   True\n",
       "1  x  x  x  x  o  o  o  x  o   True\n",
       "2  x  x  x  x  o  o  o  o  x   True\n",
       "3  x  x  x  x  o  o  o  b  b   True\n",
       "4  x  x  x  x  o  o  b  o  b   True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = ttt.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unused\n",
    "#ttt_dummies= pd.get_dummies(ttt.columns, prefix='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_BL</th>\n",
       "      <th>pos_BM</th>\n",
       "      <th>pos_BR</th>\n",
       "      <th>pos_ML</th>\n",
       "      <th>pos_MM</th>\n",
       "      <th>pos_MR</th>\n",
       "      <th>pos_TL</th>\n",
       "      <th>pos_TM</th>\n",
       "      <th>pos_TR</th>\n",
       "      <th>pos_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos_BL  pos_BM  pos_BR  pos_ML  pos_MM  pos_MR  pos_TL  pos_TM  pos_TR  \\\n",
       "0       0       0       0       0       0       0       1       0       0   \n",
       "1       0       0       0       0       0       0       0       1       0   \n",
       "2       0       0       0       0       0       0       0       0       1   \n",
       "3       0       0       0       1       0       0       0       0       0   \n",
       "4       0       0       0       0       1       0       0       0       0   \n",
       "5       0       0       0       0       0       1       0       0       0   \n",
       "6       1       0       0       0       0       0       0       0       0   \n",
       "7       0       1       0       0       0       0       0       0       0   \n",
       "8       0       0       1       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pos_class  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TL', 'TM', 'TR', 'ML', 'MM', 'MR', 'BL', 'BM', 'BR', 'class'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ttt.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(ttt[['TL', 'TM', 'TR', 'ML', 'MM', 'MR', 'BL', 'BM', 'BR', 'class']]).toarray())\n",
    "# merge with main df on key values\n",
    "ttt_OHE = ttt.join(enc_df)\n",
    "ttt_OHE.drop(columns = ['TL', 'TM', 'TR', 'ML', 'MM', 'MR', 'BL', 'BM', 'BR', 'class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   19   20   21   22  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  1.0  0.0  1.0   \n",
       "1  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  1.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  1.0  0.0  0.0  1.0   \n",
       "3  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  1.0  0.0  1.0  0.0   \n",
       "4  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "    23   24   25   26   27   28  \n",
       "0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "1  1.0  0.0  1.0  0.0  0.0  1.0  \n",
       "2  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "3  0.0  1.0  0.0  0.0  0.0  1.0  \n",
       "4  0.0  1.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt_OHE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = ttt_OHE[[27, 28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = ttt_OHE.drop(columns = [27, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   17   18   19   20  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "1  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "3  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "4  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "\n",
       "    21   22   23   24   25   26  \n",
       "0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "2  0.0  1.0  0.0  0.0  0.0  1.0  \n",
       "3  1.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    27   28\n",
       "0  0.0  1.0\n",
       "1  0.0  1.0\n",
       "2  0.0  1.0\n",
       "3  0.0  1.0\n",
       "4  0.0  1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>1.379504</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>1.379504</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>1.682855</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>1.916552</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>-0.879815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>1.916552</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>1.379504</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>1.916552</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>-0.879815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5        6   \\\n",
       "0 -0.52177 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.52177   \n",
       "1 -0.52177 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.52177   \n",
       "2 -0.52177 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.52177   \n",
       "3 -0.52177 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.52177   \n",
       "4 -0.52177 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.52177   \n",
       "\n",
       "         7         8         9   ...        17        18        19        20  \\\n",
       "0 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770 -0.733294  1.136603   \n",
       "1 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709 -0.879815   \n",
       "2 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709 -0.879815   \n",
       "3 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709 -0.879815   \n",
       "4 -0.733294  1.136603 -0.594228  ... -0.807294  1.916552 -0.733294 -0.879815   \n",
       "\n",
       "         21        22        23        24        25        26  \n",
       "0 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n",
       "1 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n",
       "2 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n",
       "3  1.682855 -0.724898 -0.807294  1.916552 -0.733294 -0.879815  \n",
       "4 -0.594228  1.379504 -0.807294  1.916552 -0.733294 -0.879815  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a scaler object\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler\n",
    "# fit and transform the data\n",
    "X_std = pd.DataFrame(std_scaler.fit_transform(X_df))\n",
    "y_std = pd.DataFrame(std_scaler.fit_transform(y_df))\n",
    "X_std.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Neural Network\n",
    "\n",
    "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
    "\n",
    "1. Split the training and test data.\n",
    "1. Create a `Sequential` model.\n",
    "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
    "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
    "1. Fit the training data.\n",
    "1. Evaluate your neural network model with the test data.\n",
    "1. Save your model as `tic-tac-toe.model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(X_std, y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>1.682855</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>1.682855</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>1.379504</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>1.682855</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>1.916552</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>-0.879815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807294</td>\n",
       "      <td>-0.52177</td>\n",
       "      <td>-0.733294</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>-0.594228</td>\n",
       "      <td>-0.724898</td>\n",
       "      <td>1.238706</td>\n",
       "      <td>-0.521770</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>-0.879815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5        6   \\\n",
       "22  -0.52177 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.52177   \n",
       "229 -0.52177 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.52177   \n",
       "830 -0.52177  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.52177   \n",
       "332 -0.52177  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.52177   \n",
       "647 -0.52177 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.52177   \n",
       "\n",
       "           7         8         9   ...        17       18        19        20  \\\n",
       "22  -0.733294  1.136603 -0.594228  ...  1.238706 -0.52177  1.363709 -0.879815   \n",
       "229 -0.733294  1.136603 -0.594228  ... -0.807294 -0.52177  1.363709 -0.879815   \n",
       "830  1.363709 -0.879815 -0.594228  ... -0.807294 -0.52177 -0.733294  1.136603   \n",
       "332  1.363709 -0.879815 -0.594228  ... -0.807294 -0.52177 -0.733294  1.136603   \n",
       "647  1.363709 -0.879815 -0.594228  ... -0.807294 -0.52177 -0.733294  1.136603   \n",
       "\n",
       "           21        22        23        24        25        26  \n",
       "22  -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n",
       "229  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n",
       "830  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n",
       "332 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n",
       "647 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'],\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: inputs=           0         1         2         3         4         5         6   \\\n22  -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n229 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n830 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n332 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n647 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n265 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n744 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n175 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294 -0.521770   \n344 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n860 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n565  1.916552 -0.733294 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n832 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n502  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n210 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294  1.916552   \n215 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294  1.916552   \n510  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n349 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706  1.916552   \n864 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n55  -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n457 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n493  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n501  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n412 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294  1.916552   \n828 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n685 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294 -0.521770   \n284 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294  1.916552   \n925  1.916552 -0.733294 -0.879815 -0.594228  1.379504 -0.807294  1.916552   \n643 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n705 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n640 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n..        ...       ...       ...       ...       ...       ...       ...   \n806 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n324 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n290 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294  1.916552   \n492  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n718 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n519  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706  1.916552   \n787 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706  1.916552   \n776 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n147 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294 -0.521770   \n637 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n25  -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n237 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n241 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n407 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n248 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n445 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n872 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294  1.916552   \n665 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706  1.916552   \n770 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n214 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294  1.916552   \n347 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706  1.916552   \n487  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n13  -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n585  1.916552 -0.733294 -0.879815 -0.594228  1.379504 -0.807294  1.916552   \n504  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n415 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294  1.916552   \n857 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n652 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n873 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294  1.916552   \n570  1.916552 -0.733294 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n\n           7         8         9   ...        17        18        19  \\\n22  -0.733294  1.136603 -0.594228  ...  1.238706 -0.521770  1.363709   \n229 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709   \n830  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n332  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n647  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n265  1.363709 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n744 -0.733294  1.136603 -0.594228  ... -0.807294  1.916552 -0.733294   \n175  1.363709 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n344  1.363709 -0.879815  1.682855  ... -0.807294 -0.521770 -0.733294   \n860 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709   \n565  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n832  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770 -0.733294   \n502  1.363709 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n210 -0.733294 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n215 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n510  1.363709 -0.879815  1.682855  ...  1.238706 -0.521770  1.363709   \n349 -0.733294 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n864 -0.733294  1.136603  1.682855  ...  1.238706 -0.521770 -0.733294   \n55  -0.733294  1.136603  1.682855  ...  1.238706  1.916552 -0.733294   \n457 -0.733294  1.136603  1.682855  ...  1.238706  1.916552 -0.733294   \n493 -0.733294  1.136603  1.682855  ... -0.807294 -0.521770 -0.733294   \n501  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n412 -0.733294 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n828  1.363709 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n685 -0.733294  1.136603  1.682855  ...  1.238706 -0.521770 -0.733294   \n284 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n925 -0.733294 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n643  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n705 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709   \n640  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n..        ...       ...       ...  ...       ...       ...       ...   \n806 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770 -0.733294   \n324  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770  1.363709   \n290 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770  1.363709   \n492 -0.733294  1.136603 -0.594228  ...  1.238706 -0.521770  1.363709   \n718  1.363709 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n519 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770  1.363709   \n787 -0.733294 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n776  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n147  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n637  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n25  -0.733294  1.136603 -0.594228  ...  1.238706  1.916552 -0.733294   \n237 -0.733294  1.136603  1.682855  ... -0.807294 -0.521770  1.363709   \n241  1.363709 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n407 -0.733294  1.136603  1.682855  ... -0.807294 -0.521770 -0.733294   \n248  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770 -0.733294   \n445 -0.733294  1.136603  1.682855  ...  1.238706 -0.521770 -0.733294   \n872 -0.733294 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n665 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n770 -0.733294  1.136603  1.682855  ...  1.238706  1.916552 -0.733294   \n214 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n347 -0.733294 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n487 -0.733294  1.136603 -0.594228  ... -0.807294  1.916552 -0.733294   \n13  -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709   \n585 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n504  1.363709 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n415 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n857 -0.733294  1.136603 -0.594228  ...  1.238706 -0.521770  1.363709   \n652  1.363709 -0.879815  1.682855  ...  1.238706 -0.521770  1.363709   \n873 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n570  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n\n           20        21        22        23        24        25        26  \n22  -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n229 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n830  1.136603  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n332  1.136603 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n647  1.136603 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n265 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n744 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n175 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n344  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n860 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n565 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n832  1.136603 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n502 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n210 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n215  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n510 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n349 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n864  1.136603  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n55  -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n457 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n493  1.136603 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n501 -0.879815 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n412 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n828 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n685  1.136603 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n284  1.136603  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n925 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n643  1.136603 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n705 -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n640  1.136603  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n..        ...       ...       ...       ...       ...       ...       ...  \n806  1.136603 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n324 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n290 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n492 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n718 -0.879815  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n519 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n787 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n776 -0.879815 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n147 -0.879815  1.682855 -0.724898 -0.807294  1.916552 -0.733294 -0.879815  \n637 -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n25  -0.879815 -0.594228  1.379504 -0.807294  1.916552 -0.733294 -0.879815  \n237 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n241 -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n407  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n248  1.136603  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n445  1.136603 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n872 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n665  1.136603 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n770 -0.879815  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n214  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n347 -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n487 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n13  -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n585  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n504 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n415  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n857 -0.879815  1.682855 -0.724898 -0.807294  1.916552 -0.733294 -0.879815  \n652 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n873  1.136603 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n570  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n\n[718 rows x 27 columns]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f799c55326df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/lab_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/lab_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2344\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2347\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2525\u001b[0m     \u001b[0;31m# or lists of arrays, and extract a flat list of inputs from the passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m     \u001b[0;31m# structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m     \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_input_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lab_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mvalidate_input_types\u001b[0;34m(inp, orig_inp, allow_dict, field_name)\u001b[0m\n\u001b[1;32m   1243\u001b[0m     raise ValueError(\n\u001b[1;32m   1244\u001b[0m         \u001b[0;34m'Please provide as model inputs either a single array or a list of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m         'arrays. You passed: {}={}'.format(field_name, orig_inp))\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: inputs=           0         1         2         3         4         5         6   \\\n22  -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n229 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n830 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n332 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n647 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n265 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n744 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n175 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294 -0.521770   \n344 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n860 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n565  1.916552 -0.733294 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n832 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n502  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n210 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294  1.916552   \n215 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294  1.916552   \n510  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n349 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706  1.916552   \n864 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n55  -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n457 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n493  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n501  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n412 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294  1.916552   \n828 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n685 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294 -0.521770   \n284 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294  1.916552   \n925  1.916552 -0.733294 -0.879815 -0.594228  1.379504 -0.807294  1.916552   \n643 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n705 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n640 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n..        ...       ...       ...       ...       ...       ...       ...   \n806 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n324 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n290 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294  1.916552   \n492  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n718 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n519  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706  1.916552   \n787 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706  1.916552   \n776 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n147 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294 -0.521770   \n637 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n25  -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n237 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n241 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n407 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n248 -0.521770 -0.733294  1.136603  1.682855 -0.724898 -0.807294 -0.521770   \n445 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n872 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294  1.916552   \n665 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706  1.916552   \n770 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n214 -0.521770 -0.733294  1.136603 -0.594228  1.379504 -0.807294  1.916552   \n347 -0.521770  1.363709 -0.879815 -0.594228 -0.724898  1.238706  1.916552   \n487  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n13  -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n585  1.916552 -0.733294 -0.879815 -0.594228  1.379504 -0.807294  1.916552   \n504  1.916552 -0.733294 -0.879815 -0.594228 -0.724898  1.238706 -0.521770   \n415 -0.521770  1.363709 -0.879815 -0.594228  1.379504 -0.807294  1.916552   \n857 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294 -0.521770   \n652 -0.521770 -0.733294  1.136603 -0.594228 -0.724898  1.238706 -0.521770   \n873 -0.521770  1.363709 -0.879815  1.682855 -0.724898 -0.807294  1.916552   \n570  1.916552 -0.733294 -0.879815 -0.594228  1.379504 -0.807294 -0.521770   \n\n           7         8         9   ...        17        18        19  \\\n22  -0.733294  1.136603 -0.594228  ...  1.238706 -0.521770  1.363709   \n229 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709   \n830  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n332  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n647  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n265  1.363709 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n744 -0.733294  1.136603 -0.594228  ... -0.807294  1.916552 -0.733294   \n175  1.363709 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n344  1.363709 -0.879815  1.682855  ... -0.807294 -0.521770 -0.733294   \n860 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709   \n565  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n832  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770 -0.733294   \n502  1.363709 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n210 -0.733294 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n215 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n510  1.363709 -0.879815  1.682855  ...  1.238706 -0.521770  1.363709   \n349 -0.733294 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n864 -0.733294  1.136603  1.682855  ...  1.238706 -0.521770 -0.733294   \n55  -0.733294  1.136603  1.682855  ...  1.238706  1.916552 -0.733294   \n457 -0.733294  1.136603  1.682855  ...  1.238706  1.916552 -0.733294   \n493 -0.733294  1.136603  1.682855  ... -0.807294 -0.521770 -0.733294   \n501  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n412 -0.733294 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n828  1.363709 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n685 -0.733294  1.136603  1.682855  ...  1.238706 -0.521770 -0.733294   \n284 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n925 -0.733294 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n643  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n705 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709   \n640  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n..        ...       ...       ...  ...       ...       ...       ...   \n806 -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770 -0.733294   \n324  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770  1.363709   \n290 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770  1.363709   \n492 -0.733294  1.136603 -0.594228  ...  1.238706 -0.521770  1.363709   \n718  1.363709 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n519 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770  1.363709   \n787 -0.733294 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n776  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n147  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n637  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770  1.363709   \n25  -0.733294  1.136603 -0.594228  ...  1.238706  1.916552 -0.733294   \n237 -0.733294  1.136603  1.682855  ... -0.807294 -0.521770  1.363709   \n241  1.363709 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n407 -0.733294  1.136603  1.682855  ... -0.807294 -0.521770 -0.733294   \n248  1.363709 -0.879815 -0.594228  ...  1.238706 -0.521770 -0.733294   \n445 -0.733294  1.136603  1.682855  ...  1.238706 -0.521770 -0.733294   \n872 -0.733294 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n665 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n770 -0.733294  1.136603  1.682855  ...  1.238706  1.916552 -0.733294   \n214 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n347 -0.733294 -0.879815 -0.594228  ...  1.238706  1.916552 -0.733294   \n487 -0.733294  1.136603 -0.594228  ... -0.807294  1.916552 -0.733294   \n13  -0.733294  1.136603 -0.594228  ... -0.807294 -0.521770  1.363709   \n585 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n504  1.363709 -0.879815 -0.594228  ... -0.807294  1.916552 -0.733294   \n415 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n857 -0.733294  1.136603 -0.594228  ...  1.238706 -0.521770  1.363709   \n652  1.363709 -0.879815  1.682855  ...  1.238706 -0.521770  1.363709   \n873 -0.733294 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n570  1.363709 -0.879815 -0.594228  ... -0.807294 -0.521770 -0.733294   \n\n           20        21        22        23        24        25        26  \n22  -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n229 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n830  1.136603  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n332  1.136603 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n647  1.136603 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n265 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n744 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n175 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n344  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n860 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n565 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n832  1.136603 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n502 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n210 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n215  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n510 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n349 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n864  1.136603  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n55  -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n457 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n493  1.136603 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n501 -0.879815 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n412 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n828 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n685  1.136603 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n284  1.136603  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n925 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n643  1.136603 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n705 -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n640  1.136603  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n..        ...       ...       ...       ...       ...       ...       ...  \n806  1.136603 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n324 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n290 -0.879815  1.682855 -0.724898 -0.807294 -0.521770 -0.733294  1.136603  \n492 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n718 -0.879815  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n519 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n787 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n776 -0.879815 -0.594228 -0.724898  1.238706  1.916552 -0.733294 -0.879815  \n147 -0.879815  1.682855 -0.724898 -0.807294  1.916552 -0.733294 -0.879815  \n637 -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n25  -0.879815 -0.594228  1.379504 -0.807294  1.916552 -0.733294 -0.879815  \n237 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n241 -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n407  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n248  1.136603  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n445  1.136603 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n872 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n665  1.136603 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n770 -0.879815  1.682855 -0.724898 -0.807294 -0.521770  1.363709 -0.879815  \n214  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n347 -0.879815 -0.594228  1.379504 -0.807294 -0.521770  1.363709 -0.879815  \n487 -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n13  -0.879815 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n585  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n504 -0.879815 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n415  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n857 -0.879815  1.682855 -0.724898 -0.807294  1.916552 -0.733294 -0.879815  \n652 -0.879815 -0.594228  1.379504 -0.807294 -0.521770 -0.733294  1.136603  \n873  1.136603 -0.594228 -0.724898  1.238706 -0.521770  1.363709 -0.879815  \n570  1.136603 -0.594228 -0.724898  1.238706 -0.521770 -0.733294  1.136603  \n\n[718 rows x 27 columns]"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tic-tac-toe.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions\n",
    "\n",
    "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This are probability distritutions. A tensor that need to be unrooled'''\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improve Your Model\n",
    "\n",
    "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
    "\n",
    "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
    "\n",
    "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
    "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
    "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
    "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which approach(es) did you find helpful to improve your model performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lab_env]",
   "language": "python",
   "name": "conda-env-lab_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
